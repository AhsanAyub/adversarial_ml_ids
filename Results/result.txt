==== batch: 64 | Dataset: 34,220 | Binary Classification ====

Artificial Neural Network
              precision    recall  f1-score   support

           0     0.9617    0.8728    0.9151      4000
           1     0.8416    0.9511    0.8930      2844

    accuracy                         0.9053      6844
   macro avg     0.9017    0.9119    0.9041      6844
weighted avg     0.9118    0.9053    0.9059      6844

Confusion Matrix:
 [[3491  509]
 [ 139 2705]]
Accuracy:  0.9053185271770894
F1:  0.8930340046219873
Precison:  0.8416303671437461
Recall:  0.9511251758087201

==== batch: 64 | Dataset: 34,220 | Binary Classification | Scaled ====

Artificial Neural Network
              precision    recall  f1-score   support

           0     0.9544    0.9892    0.9715      4000
           1     0.9841    0.9335    0.9581      2844

    accuracy                         0.9661      6844
   macro avg     0.9692    0.9614    0.9648      6844
weighted avg     0.9667    0.9661    0.9660      6844

Confusion Matrix:
 [[3957   43]
 [ 189 2655]]
Accuracy:  0.9661016949152542
F1:  0.9581378563695416
Precison:  0.9840622683469237
Recall:  0.9335443037974683

===== Decision Tree | Dataset: 34,220 | Binary Classification =====

Accuracy:  0.8898305084745763
F1:  0.8450613705520651
Precision:  0.9917528479775765
Recall:  0.7410689170182841

[0.8686440677966102, 0.8657218001168907, 0.8667445938047925, 0.880187025131502, 0.9678550555230859]
[0.9879578524836929, 0.9918242207460398, 0.999482936918304, 0.9870067372473532, 0.9924924924924925]
[0.6923347398030942, 0.6824894514767933, 0.679676511954993, 0.7211673699015471, 0.929676511954993]
[0.8141409964854248, 0.8085815455113519, 0.8091251569694433, 0.8334010564811053, 0.9600580973129994]

===== Decision Tree | Dataset: 34,220 | Binary Classification | Scaled =====

Accuracy:  0.8810344827586206
F1:  0.8319308963288237
Precision:  0.9863850672690218
Recall:  0.7246835443037974

[0.8459964932787843, 0.8658679135008767, 0.8676212741087084, 0.8796025715955581, 0.9460841613091759]
[0.9896061269146609, 0.9903258655804481, 0.9994845360824742, 0.9846449136276392, 0.9678638941398866]
[0.6360759493670886, 0.6838959212376934, 0.6817862165963432, 0.7215189873417721, 0.90014064697609]
[0.7744006849315068, 0.8090682196339435, 0.81061872909699, 0.8327922077922079, 0.9327746401894699]


========== Adversarial Example | Jacobian-based Saliency Map | 34K ==========
Performance when using actual testing instances
              precision    recall  f1-score   support

           0     0.9895    0.9665    0.9779      4000
           1     0.9544    0.9856    0.9697      2844

   micro avg     0.9744    0.9744    0.9744      6844
   macro avg     0.9719    0.9760    0.9738      6844
weighted avg     0.9749    0.9744    0.9745      6844

Confusion Matrix (Actual):
 [[3866  134]
 [  41 2803]]
Accuracy (Actual):  0.9744301578024547
F1 (Actual):  0.9697284206884621
Precison (Actual):  0.9543752128021791
Recall (Actual):  0.9855836849507735

Performance when using adversarial testing instances
  'precision', 'predicted', average, warn_for)
              precision    recall  f1-score   support

           0     0.5845    1.0000    0.7377      4000
           1     0.0000    0.0000    0.0000      2844

   micro avg     0.5845    0.5845    0.5845      6844
   macro avg     0.2922    0.5000    0.3689      6844
weighted avg     0.3416    0.5845    0.4312      6844

Confusion Matrix (Adversarial):
 [[4000    0]
 [2844    0]]
Accuracy (Adversarial):  0.5844535359438925
F1 (Adversarial):  0.0
Precison (Adversarial):  0.0
Recall (Adversarial):  0.0

========== Adversarial Example | Jacobian-based Saliency Map | CICIDS | 950K ==========

Layer (type)                 Output Shape              Param #   
=================================================================
dense_1 (Dense)              (None, 40)                3240      
_________________________________________________________________
dense_2 (Dense)              (None, 40)                1640      
_________________________________________________________________
dense_3 (Dense)              (None, 1)                 41        
=================================================================
Total params: 4,921
Trainable params: 4,921
Non-trainable params: 0
_________________________________________________________________
None
Performance when using actual testing instances
              precision    recall  f1-score   support

           0     0.9957    0.9951    0.9954    110246
           1     0.9932    0.9940    0.9936     79553

   micro avg     0.9946    0.9946    0.9946    189799
   macro avg     0.9944    0.9946    0.9945    189799
weighted avg     0.9946    0.9946    0.9946    189799

Confusion Matrix:
 [[109704    542]
 [   474  79079]]
Accuracy:  0.9946469686352405
F1:  0.9936170480103534
Precison:  0.9931927506562339
Recall:  0.9940417080436942
Performance when using adversarial testing instances
              precision    recall  f1-score   support

           0     0.5809    1.0000    0.7349    110246
           1     0.0000    0.0000    0.0000     79553

   micro avg     0.5809    0.5809    0.5809    189799
   macro avg     0.2904    0.5000    0.3674    189799
weighted avg     0.3374    0.5809    0.4269    189799

Confusion Matrix:
 [[110246      0]
 [ 79553      0]]
Accuracy:  0.5808565903929946
F1:  0.0
Precison:  0.0
Recall:  0.0

========== Adversarial Example | Jacobian-based Saliency Map | TRAbID | 18K Dataset ==========

_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_1 (Dense)              (None, 22)                968       
_________________________________________________________________
dense_2 (Dense)              (None, 22)                506       
_________________________________________________________________
dense_3 (Dense)              (None, 1)                 23        
=================================================================
Total params: 1,497
Trainable params: 1,497
Non-trainable params: 0
_________________________________________________________________
None
Performance when using actual testing instances
              precision    recall  f1-score   support

           0     0.9978    0.9973    0.9975      1832
           1     0.9973    0.9978    0.9975      1831

   micro avg     0.9975    0.9975    0.9975      3663
   macro avg     0.9975    0.9975    0.9975      3663
weighted avg     0.9975    0.9975    0.9975      3663

Confusion Matrix:
 [[1827    5]
 [   4 1827]]
Accuracy:  0.9975429975429976
F1:  0.9975429975429975
Precison:  0.9972707423580786
Recall:  0.997815401419989

Performance when using adversarial testing instances
              precision    recall  f1-score   support

           0     0.0000    0.0000    0.0000      1832
           1     0.4999    1.0000    0.6665      1831

   micro avg     0.4999    0.4999    0.4999      3663
   macro avg     0.2499    0.5000    0.3333      3663
weighted avg     0.2499    0.4999    0.3332      3663

Confusion Matrix:
 [[   0 1832]
 [   0 1831]]
Accuracy:  0.49986349986349987
F1:  0.6665453221696396
Precison:  0.49986349986349987
Recall:  1.0